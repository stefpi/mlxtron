# MLXtron

4D parallelizable training for models using MLX. Based on [Picotron](https://github.com/huggingface/picotron).

very minimal implementation and probably will only support LLama architecture for now. If I am goated enough then maybe it will evolve to be MLX-Nano-Tron.

